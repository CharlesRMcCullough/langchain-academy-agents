{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:02:30.413847Z",
     "start_time": "2024-11-30T15:02:30.118863Z"
    }
   },
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:05:57.495771Z",
     "start_time": "2024-11-30T15:05:48.739511Z"
    }
   },
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GROQ_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:06:02.168894Z",
     "start_time": "2024-11-30T15:06:02.126092Z"
    }
   },
   "source": [
    "llm = ChatGroq(model=\"gemma2-9b-it\", temperature=0)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:06:04.689122Z",
     "start_time": "2024-11-30T15:06:04.686984Z"
    }
   },
   "source": [
    "def reverse_string(s):\n",
    "    \"\"\"Reverses the input string.\"\"\"\n",
    "    return s[::-1]\n",
    "\n",
    "def capitalize_string(s):\n",
    "    \"\"\"Capsitizes the input string.\"\"\"\n",
    "    return s[:1].upper() + s[1:]\n",
    "\n",
    "def to_lowercase(s):\n",
    "    \"\"\"Converts the input string to lowercase.\"\"\"\n",
    "    return s.lower()\n",
    "\n",
    "def to_uppercase(s):\n",
    "    \"\"\"Converts the input string to uppercase.\"\"\"\n",
    "    return s.upper()\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:06:07.985662Z",
     "start_time": "2024-11-30T15:06:07.945279Z"
    }
   },
   "source": [
    "tools = [reverse_string, capitalize_string, to_lowercase, to_uppercase]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:07:25.076825Z",
     "start_time": "2024-11-30T15:07:25.074603Z"
    }
   },
   "source": [
    "sys_msg = SystemMessage(content=\"Your are a helpful assistant tasked with performing string functions\")\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:06:51.726762Z",
     "start_time": "2024-11-30T15:06:51.724783Z"
    }
   },
   "source": [
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Agent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:07:07.369195Z",
     "start_time": "2024-11-30T15:07:07.342058Z"
    }
   },
   "source": [
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Define nodees: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edgesL these determine how the flow moves\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition,)\n",
    "\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "react_graph = builder.compile(checkpointer=memory)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:07:10.816144Z",
     "start_time": "2024-11-30T15:07:10.814466Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:07:31.027873Z",
     "start_time": "2024-11-30T15:07:30.159311Z"
    }
   },
   "source": [
    "messages = [HumanMessage(content=\"Reverse this string 'Charles McCullough'\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Reverse this string 'Charles McCullough'\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Reverse this string 'Charles McCullough'\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  reverse_string (call_mqxz)\n",
      " Call ID: call_mqxz\n",
      "  Args:\n",
      "    s: Charles McCullough\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: reverse_string\n",
      "\n",
      "hguolluCcM selrahC\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "hguolluCcM selrahC\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:07:36.252501Z",
     "start_time": "2024-11-30T15:07:35.553409Z"
    }
   },
   "source": [
    "messages = [HumanMessage(content=\"Now convert the reversed string to upper case.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Reverse this string 'Charles McCullough'\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Reverse this string 'Charles McCullough'\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  reverse_string (call_mqxz)\n",
      " Call ID: call_mqxz\n",
      "  Args:\n",
      "    s: Charles McCullough\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: reverse_string\n",
      "\n",
      "hguolluCcM selrahC\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "hguolluCcM selrahC\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Now convert the reversed string to upper case.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  to_uppercase (call_pwn3)\n",
      " Call ID: call_pwn3\n",
      "  Args:\n",
      "    s: hguolluCcM selrahC\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: to_uppercase\n",
      "\n",
      "HGUOLLUCCM SELRAHC\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "HGUOLLUCCM SELRAHC\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:07:40.122300Z",
     "start_time": "2024-11-30T15:07:39.046876Z"
    }
   },
   "source": [
    "messages = [HumanMessage(content=\"Now reverse the string again and convert it to lowercase.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool-use>{\"tool_call\":{\"id\":\"call_y78j\",\"type\":\"function\",\"function\":{\"name\":\"reverse_string\"},\"parameters\":{\"s\":\"HGUOLLUCCM SELRAHC\"}},\"parameters\":{\"s\":\"HGUOLLUCCM SELRAHC\"}}}</tool-use>\\n'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m messages \u001B[38;5;241m=\u001B[39m [HumanMessage(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNow reverse the string again and convert it to lowercase.\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[0;32m----> 2\u001B[0m messages \u001B[38;5;241m=\u001B[39m react_graph\u001B[38;5;241m.\u001B[39minvoke({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages}, config)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m      4\u001B[0m     m\u001B[38;5;241m.\u001B[39mpretty_print()\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1927\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001B[0m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1926\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 1927\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(\n\u001B[1;32m   1928\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   1929\u001B[0m     config,\n\u001B[1;32m   1930\u001B[0m     stream_mode\u001B[38;5;241m=\u001B[39mstream_mode,\n\u001B[1;32m   1931\u001B[0m     output_keys\u001B[38;5;241m=\u001B[39moutput_keys,\n\u001B[1;32m   1932\u001B[0m     interrupt_before\u001B[38;5;241m=\u001B[39minterrupt_before,\n\u001B[1;32m   1933\u001B[0m     interrupt_after\u001B[38;5;241m=\u001B[39minterrupt_after,\n\u001B[1;32m   1934\u001B[0m     debug\u001B[38;5;241m=\u001B[39mdebug,\n\u001B[1;32m   1935\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   1936\u001B[0m ):\n\u001B[1;32m   1937\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1938\u001B[0m         latest \u001B[38;5;241m=\u001B[39m chunk\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1647\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001B[0m\n\u001B[1;32m   1641\u001B[0m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[1;32m   1642\u001B[0m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001B[39;00m\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;66;03m# channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[1;32m   1644\u001B[0m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[1;32m   1645\u001B[0m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps\u001B[39;00m\n\u001B[1;32m   1646\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels):\n\u001B[0;32m-> 1647\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mtick(\n\u001B[1;32m   1648\u001B[0m             loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m   1649\u001B[0m             timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[1;32m   1650\u001B[0m             retry_policy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_policy,\n\u001B[1;32m   1651\u001B[0m             get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[1;32m   1652\u001B[0m         ):\n\u001B[1;32m   1653\u001B[0m             \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[1;32m   1654\u001B[0m             \u001B[38;5;28;01myield from\u001B[39;00m output()\n\u001B[1;32m   1655\u001B[0m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langgraph/pregel/runner.py:104\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[1;32m    102\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 104\u001B[0m     run_with_retry(t, retry_policy, writer\u001B[38;5;241m=\u001B[39mwriter)\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy, writer)\u001B[0m\n\u001B[1;32m     38\u001B[0m task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m task\u001B[38;5;241m.\u001B[39mproc\u001B[38;5;241m.\u001B[39minvoke(task\u001B[38;5;241m.\u001B[39minput, config)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# if successful, end\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langgraph/utils/runnable.py:410\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    408\u001B[0m context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, config)\n\u001B[1;32m    409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 410\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(step\u001B[38;5;241m.\u001B[39minvoke, \u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    412\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(step\u001B[38;5;241m.\u001B[39minvoke, \u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langgraph/utils/runnable.py:184\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    183\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, config)\n\u001B[0;32m--> 184\u001B[0m     ret \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc, \u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse:\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m, in \u001B[0;36massistant\u001B[0;34m(state)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21massistant\u001B[39m(state: MessagesState):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [llm_with_tools\u001B[38;5;241m.\u001B[39minvoke([sys_msg] \u001B[38;5;241m+\u001B[39m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m])]}\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langchain_core/runnables/base.py:5354\u001B[0m, in \u001B[0;36mRunnableBindingBase.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   5348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m   5349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5350\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   5351\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   5352\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   5353\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Output:\n\u001B[0;32m-> 5354\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbound\u001B[38;5;241m.\u001B[39minvoke(\n\u001B[1;32m   5355\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   5356\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_configs(config),\n\u001B[1;32m   5357\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs},\n\u001B[1;32m   5358\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:286\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    277\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    282\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m    283\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    285\u001B[0m         ChatGeneration,\n\u001B[0;32m--> 286\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_prompt(\n\u001B[1;32m    287\u001B[0m             [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_input(\u001B[38;5;28minput\u001B[39m)],\n\u001B[1;32m    288\u001B[0m             stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[1;32m    289\u001B[0m             callbacks\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    290\u001B[0m             tags\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    291\u001B[0m             metadata\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    292\u001B[0m             run_name\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    293\u001B[0m             run_id\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    294\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    295\u001B[0m         )\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    296\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:786\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    778\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    779\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    780\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    784\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    785\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(prompt_messages, stop\u001B[38;5;241m=\u001B[39mstop, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:643\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    641\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n\u001B[1;32m    642\u001B[0m             run_managers[i]\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[0;32m--> 643\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    644\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    645\u001B[0m     LLMResult(generations\u001B[38;5;241m=\u001B[39m[res\u001B[38;5;241m.\u001B[39mgenerations], llm_output\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mllm_output)  \u001B[38;5;66;03m# type: ignore[list-item]\u001B[39;00m\n\u001B[1;32m    646\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\n\u001B[1;32m    647\u001B[0m ]\n\u001B[1;32m    648\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:633\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    631\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    632\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 633\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_with_cache(\n\u001B[1;32m    634\u001B[0m                 m,\n\u001B[1;32m    635\u001B[0m                 stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[1;32m    636\u001B[0m                 run_manager\u001B[38;5;241m=\u001B[39mrun_managers[i] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    637\u001B[0m                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    638\u001B[0m             )\n\u001B[1;32m    639\u001B[0m         )\n\u001B[1;32m    640\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    641\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:851\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    849\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    850\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 851\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[1;32m    852\u001B[0m             messages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    853\u001B[0m         )\n\u001B[1;32m    854\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    855\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/langchain_groq/chat_models.py:474\u001B[0m, in \u001B[0;36mChatGroq._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    469\u001B[0m message_dicts, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_message_dicts(messages, stop)\n\u001B[1;32m    470\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    471\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    473\u001B[0m }\n\u001B[0;32m--> 474\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(messages\u001B[38;5;241m=\u001B[39mmessage_dicts, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m    475\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_chat_result(response)\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/groq/resources/chat/completions.py:298\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    186\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    187\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m    188\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;124;03m    Creates a model response for the given chat conversation.\u001B[39;00m\n\u001B[1;32m    190\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001B[39;00m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[1;32m    299\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/openai/v1/chat/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    300\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[1;32m    301\u001B[0m             {\n\u001B[1;32m    302\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages,\n\u001B[1;32m    303\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model,\n\u001B[1;32m    304\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: frequency_penalty,\n\u001B[1;32m    305\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction_call\u001B[39m\u001B[38;5;124m\"\u001B[39m: function_call,\n\u001B[1;32m    306\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunctions\u001B[39m\u001B[38;5;124m\"\u001B[39m: functions,\n\u001B[1;32m    307\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogit_bias\u001B[39m\u001B[38;5;124m\"\u001B[39m: logit_bias,\n\u001B[1;32m    308\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: logprobs,\n\u001B[1;32m    309\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_tokens,\n\u001B[1;32m    310\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m\"\u001B[39m: n,\n\u001B[1;32m    311\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparallel_tool_calls\u001B[39m\u001B[38;5;124m\"\u001B[39m: parallel_tool_calls,\n\u001B[1;32m    312\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpresence_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: presence_penalty,\n\u001B[1;32m    313\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_format\u001B[39m\u001B[38;5;124m\"\u001B[39m: response_format,\n\u001B[1;32m    314\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m: seed,\n\u001B[1;32m    315\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m: stop,\n\u001B[1;32m    316\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream,\n\u001B[1;32m    317\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m: temperature,\n\u001B[1;32m    318\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtool_choice\u001B[39m\u001B[38;5;124m\"\u001B[39m: tool_choice,\n\u001B[1;32m    319\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtools\u001B[39m\u001B[38;5;124m\"\u001B[39m: tools,\n\u001B[1;32m    320\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_logprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_logprobs,\n\u001B[1;32m    321\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_p\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_p,\n\u001B[1;32m    322\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m: user,\n\u001B[1;32m    323\u001B[0m             },\n\u001B[1;32m    324\u001B[0m             completion_create_params\u001B[38;5;241m.\u001B[39mCompletionCreateParams,\n\u001B[1;32m    325\u001B[0m         ),\n\u001B[1;32m    326\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[1;32m    327\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    328\u001B[0m         ),\n\u001B[1;32m    329\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mChatCompletion,\n\u001B[1;32m    330\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    331\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mStream[ChatCompletionChunk],\n\u001B[1;32m    332\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/groq/_base_client.py:1263\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1250\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1251\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1258\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1259\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1260\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1261\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1262\u001B[0m     )\n\u001B[0;32m-> 1263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/groq/_base_client.py:955\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    952\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    953\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 955\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    956\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m    957\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m    958\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    959\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m    960\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m    961\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/LangchainAcademy/lib/python3.11/site-packages/groq/_base_client.py:1058\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1055\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1057\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1058\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1061\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1062\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1066\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1067\u001B[0m )\n",
      "\u001B[0;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool-use>{\"tool_call\":{\"id\":\"call_y78j\",\"type\":\"function\",\"function\":{\"name\":\"reverse_string\"},\"parameters\":{\"s\":\"HGUOLLUCCM SELRAHC\"}},\"parameters\":{\"s\":\"HGUOLLUCCM SELRAHC\"}}}</tool-use>\\n'}}"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:07:46.953512Z",
     "start_time": "2024-11-30T15:07:46.393038Z"
    }
   },
   "source": [
    "messages = [HumanMessage(content=\"Now capitize the string.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Reverse this string 'Charles McCullough'\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Reverse this string 'Charles McCullough'\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  reverse_string (call_mqxz)\n",
      " Call ID: call_mqxz\n",
      "  Args:\n",
      "    s: Charles McCullough\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: reverse_string\n",
      "\n",
      "hguolluCcM selrahC\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "hguolluCcM selrahC\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Now convert the reversed string to upper case.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  to_uppercase (call_pwn3)\n",
      " Call ID: call_pwn3\n",
      "  Args:\n",
      "    s: hguolluCcM selrahC\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: to_uppercase\n",
      "\n",
      "HGUOLLUCCM SELRAHC\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "HGUOLLUCCM SELRAHC\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Now reverse the string again and convert it to lowercase.\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Now capitize the string.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  capitalize_string (call_yv3p)\n",
      " Call ID: call_yv3p\n",
      "  Args:\n",
      "    s: hguolluCcM selrahC\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: capitalize_string\n",
      "\n",
      "HguolluCcM selrahC\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "HguolluCcM selrahC\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T15:07:49.811822Z",
     "start_time": "2024-11-30T15:07:49.809616Z"
    }
   },
   "source": [
    "print(capitalize_string(\"charles mccullough\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charles mccullough\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangchainAcademy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
